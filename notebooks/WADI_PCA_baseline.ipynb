{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "from util import (\n",
    "    make_intervals,\n",
    "    compute_event_wise_metrics,\n",
    "    predict_with_PCA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare original data\n",
    "Original training data comes with the following header and lengthy column names:\n",
    "\n",
    "```\n",
    "Created: 10/9/2017 6:05:57.359 PM Malay Peninsula Standard Time                       \n",
    "Number of rows: 1.2096E+6\n",
    "Interpolation interval: 1 seconds\n",
    "\n",
    "```\n",
    "\n",
    "Please put the `prepare_WADI.sh` script in the same directory as the data and run it. Then check the checksum of processed files by running the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8d3d8b91aaf79cf845ed94fc117f3849  ./data/WADI/WADI_14days.csv\n",
      "649ec203ad98ffa2073a91e5ad51ed5e  ./data/WADI/WADI_A1_2017_attacks.csv\n",
      "2d6a4d2a44e085cd97e5e6e2dd4f7a3c  ./data/WADI/WADI_attackdata.csv\n"
     ]
    }
   ],
   "source": [
    "!md5sum ./data/WADI/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0d35aa64237db1c2e23379a9b995dafc636807cb  ./data/WADI/WADI_14days.csv\n",
      "2a1eea939e6d7b0ecaf26643afa10c720927a12e  ./data/WADI/WADI_A1_2017_attacks.csv\n",
      "c45b39752207639ac57a8cce88f0652e148203c8  ./data/WADI/WADI_attackdata.csv\n"
     ]
    }
   ],
   "source": [
    "!sha1sum ./data/WADI/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path(\"./data/WADI\")\n",
    "\n",
    "normal = pd.read_csv(\n",
    "    DATADIR / \"WADI_14days.csv\",\n",
    "    parse_dates={\"Timestamp\": [\"Date\", \"Time\"]},\n",
    "    date_format=\"%m/%d/%Y %I:%M:%S.000 %p\",\n",
    "    index_col=\"Timestamp\"\n",
    ")\n",
    "\n",
    "attack = pd.read_csv(\n",
    "    DATADIR / \"WADI_attackdata.csv\",\n",
    "    parse_dates={\"Timestamp\": [\"Date\", \"Time\"]},\n",
    "    date_format=\"%m/%d/%Y %I:%M:%S.000 %p\",\n",
    "    index_col=\"Timestamp\"\n",
    ")\n",
    "\n",
    "attacks_ts = pd.read_csv(\n",
    "    DATADIR / \"WADI_A1_2017_attacks.csv\", parse_dates=[\"StartTime\", \"EndTime\"],\n",
    "    date_format=\"%d/%m/%Y %H:%M:%S\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (normal.columns == attack.columns).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Labels\n",
    "\n",
    "Make labels using attacks' timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamination rate: 5.71\n",
      "Number of anomalous events: 14\n",
      "Min event length: 88\n",
      "Max event length: 1741\n",
      "Average event length: 711\n",
      "Median event length: 630\n"
     ]
    }
   ],
   "source": [
    "y_true_ts = np.zeros(len(attack))\n",
    "gt_intervals = []\n",
    "index = list(attack.index)\n",
    "for _, (onset, offset, *_) in attacks_ts.iterrows():\n",
    "    onset = index.index(onset)\n",
    "    offset = index.index(offset) + 1\n",
    "    y_true_ts[onset:offset] = 1\n",
    "    gt_intervals.append((onset, offset))\n",
    "y_true_ts.mean()\n",
    "y_true = y_true_ts == 1\n",
    "\n",
    "print(\"Contamination rate:\", f\"{y_true.mean()*100:.2f}\")\n",
    "print(\"Number of anomalous events:\", len(gt_intervals))\n",
    "event_lengths = np.diff(gt_intervals).reshape(-1)\n",
    "print(\"Min event length:\", np.min(event_lengths))\n",
    "print(\"Max event length:\", np.max(event_lengths))\n",
    "print(\"Average event length:\", round(np.mean(event_lengths)))\n",
    "print(\"Median event length:\", round(np.median(event_lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "MIN_SCALE = -1.\n",
    "MAX_SCALE = 1.\n",
    "\n",
    "MIN_CLIP = -5.\n",
    "MAX_CLIP = 5.\n",
    "\n",
    "PCA_N_COMP = 46 # other vlaues may also work as well\n",
    "SCORE_AGG_FN = np.mean\n",
    "SCORE_SMOOTHING_HISTORY_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1209601, 123)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"Row\",\n",
    "    \"2_LS_001_AL\",\n",
    "    \"2_LS_002_AL\",\n",
    "    \"2_P_001_STATUS\",\n",
    "    \"2_P_002_STATUS\",\n",
    "]\n",
    "X_train = (\n",
    "    normal.drop(columns=drop_cols).ffill().to_numpy().astype(np.float32)\n",
    ")\n",
    "X_test = (\n",
    "    attack.drop(columns=drop_cols).ffill().to_numpy().astype(np.float32)\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "scaler = MinMaxScaler((MIN_SCALE, MAX_SCALE))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "pca = PCA(n_components=PCA_N_COMP)\n",
    "pca.fit(X_train)\n",
    "\n",
    "residual = predict_with_PCA(\n",
    "    pca,\n",
    "    X_test.clip(min=MIN_CLIP, max=MAX_CLIP),\n",
    "    score_agg_fn=np.mean,\n",
    "    smooth_n=SCORE_SMOOTHING_HISTORY_SIZE,\n",
    ")\n",
    "scores = residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Point-wise F1 score\n",
    "We first compute the best point-wise F1 score, then we use the corresponding threshold to compute other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3744"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, scores)\n",
    "\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-10)\n",
    "round(f1_scores.max(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event-wise metrics\n",
    "For these we use the threshold that yields the best **point-wise** F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = f1_scores.argmax()\n",
    "best_threshold = thresholds[argmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-wise F1:\t\t 0.3744\n",
      "Event-wise F1 (F1_ew):\t 0.6085\n",
      "Composite F1 (F1_c):\t 0.6546\n",
      "True positive events:\t 7\n",
      "False positive events:\t 2\n"
     ]
    }
   ],
   "source": [
    "y_pred = scores >= best_threshold\n",
    "\n",
    "\n",
    "TP_ew, FP_ew, FN_ew, P_ew, R_ew, F1_ew, F1_c = compute_event_wise_metrics(\n",
    "    y_true, y_pred, gt_intervals\n",
    ")\n",
    "\n",
    "print(\"Point-wise F1:\\t\\t\", round(f1_score(y_true, y_pred), 4))\n",
    "print(\"Event-wise F1 (F1_ew):\\t\", round(F1_ew, 4))\n",
    "print(\"Composite F1 (F1_c):\\t\", round(F1_c, 4))\n",
    "print(\"True positive events:\\t\", TP_ew)\n",
    "print(\"False positive events:\\t\", FP_ew)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better composite F1 score with a smaller smoothing window\n",
    "A better **composite F1** score can be achieved by setting `SCORE_SMOOTHING_HISTORY_SIZE` to `15` instead of `30`. This will have little impact on the **point-wise F1**, but the **event-wise** score will decrease due to a higher number of false alarms at the event level.\n",
    "\n",
    "\n",
    "Please update `SCORE_SMOOTHING_HISTORY_SIZE` above and run all cells starting from **Hyperparameters**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-wise F1:\t\t 0.3825\n",
      "Event-wise F1 (F1_ew):\t 0.4704\n",
      "Composite F1 (F1_c):\t 0.7122\n",
      "True positive events:\t 8\n",
      "False positive events:\t 12\n"
     ]
    }
   ],
   "source": [
    "y_pred = scores >= best_threshold\n",
    "\n",
    "\n",
    "TP_ew, FP_ew, FN_ew, P_ew, R_ew, F1_ew, F1_c = compute_event_wise_metrics(\n",
    "    y_true, y_pred, gt_intervals\n",
    ")\n",
    "\n",
    "print(\"Point-wise F1:\\t\\t\", round(f1_score(y_true, y_pred), 4))\n",
    "print(\"Event-wise F1 (F1_ew):\\t\", round(F1_ew, 4))\n",
    "print(\"Composite F1 (F1_c):\\t\", round(F1_c, 4))\n",
    "print(\"True positive events:\\t\", TP_ew)\n",
    "print(\"False positive events:\\t\", FP_ew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
